{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GestureToEmoji_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RkR-LZ8gdKJ",
        "colab_type": "text"
      },
      "source": [
        "#Inspiration\n",
        "\n",
        "https://dev.to/devdevcharlie/play-street-fighter-with-body-movements-using-arduino-and-tensorflow-js-4kbi\n",
        "\n",
        "Built in JS with Johnny-Five and TensorFlow.js, goal is to port it to TensorFlow Lite Micro and run ML inferencing directly on an Arduino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7P8msYEMWRd",
        "colab_type": "text"
      },
      "source": [
        "# Arduino setup\n",
        "\n",
        "1. Download the Arduino IDE\n",
        "1. Install Nano 33 BLE board support via: `Tools -> Board: ... -> Board Manager ...`\n",
        "1. Install the `Arduino_LSM9DS1` library via: `Sketch -> Include Library -> Manage Libraries ...`\n",
        "1. Upload the sketch below and open the Serial Monitor.\n",
        "1. Press the button to start recording the gestue for 1 second.\n",
        "1. Repeat the above step many times, copy the output of the Serial Monitor and save as a ``.csv` file.\n",
        "1. Repeat the for all the gestures you want to train.\n",
        "1. Copy data into the notebook code cells prefixed with `%%writefile <gesture name>.csv`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCgCdOrpB1Sh",
        "colab_type": "text"
      },
      "source": [
        "# Arduino Sketch - Record Data\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "```arduino\n",
        "#include <Arduino_LSM9DS1.h>\n",
        "\n",
        "const int buttonPin = 3;     // the number of the pushbutton pin\n",
        "const int ledPin =  13;      // the number of the LED pin\n",
        "const int numSamples = 119;\n",
        "\n",
        "int previousButtonState = HIGH;\n",
        "int samplesRead = numSamples;\n",
        "\n",
        "void setup() {\n",
        "  Serial.begin(9600);\n",
        "  while (!Serial);\n",
        "\n",
        "  // initialize the LED pin as an output:\n",
        "  pinMode(ledPin, OUTPUT);\n",
        "  // initialize the pushbutton pin as an input with pullup:\n",
        "  pinMode(buttonPin, INPUT_PULLUP);\n",
        "\n",
        "  if (!IMU.begin()) {\n",
        "    Serial.println(\"Failed to initialize IMU!\");\n",
        "    while (1);\n",
        "  }\n",
        "\n",
        "  Serial.println(\"aX,aY,aZ,gX,gY,gZ\");\n",
        "}\n",
        "\n",
        "void loop() {\n",
        "  int buttonState = digitalRead(buttonPin);\n",
        "\n",
        "  if (buttonState != previousButtonState) {\n",
        "    if (buttonState == LOW) {\n",
        "      if (samplesRead == numSamples) {\n",
        "        // pressed\n",
        "        samplesRead = 0;\n",
        "      }\n",
        "    } else {\n",
        "      // released\n",
        "    }\n",
        "\n",
        "    previousButtonState = buttonState;\n",
        "  }\n",
        "\n",
        "  if (samplesRead < numSamples) {\n",
        "    if (IMU.accelerationAvailable() && IMU.gyroscopeAvailable()) {\n",
        "      float aX, aY, aZ, gX, gY, gZ;\n",
        "\n",
        "      IMU.readAcceleration(aX, aY, aZ);\n",
        "      IMU.readGyroscope(gX, gY, gZ);\n",
        "\n",
        "      samplesRead++;\n",
        "\n",
        "      Serial.print(aX, 3);\n",
        "      Serial.print(',');\n",
        "      Serial.print(aY, 3);\n",
        "      Serial.print(',');\n",
        "      Serial.print(aZ, 3);\n",
        "      Serial.print(',');\n",
        "      Serial.print(gX, 3);\n",
        "      Serial.print(',');\n",
        "      Serial.print(gY, 3);\n",
        "      Serial.print(',');\n",
        "      Serial.print(gZ, 3);\n",
        "      Serial.println();\n",
        "\n",
        "      if (samplesRead == numSamples) {\n",
        "        Serial.println();\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-",
        "colab_type": "text"
      },
      "source": [
        "# Setup Python Environment \n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab_type": "code",
        "outputId": "174d7cdf-2cbe-45d1-eac3-e705f6737075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install tensorflow==2.0.0-rc1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-rc1 in /usr/local/lib/python3.6/dist-packages (2.0.0rc1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (3.0.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.16.5)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.15.0a20190806)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc1) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc1) (0.15.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc1) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW62ifxErYG1",
        "colab_type": "text"
      },
      "source": [
        "# Gather Data\n",
        "\n",
        "1. Run the Arduino Code\n",
        "1. Push the button, make a punch gesture\n",
        "1. Repeat 10x\n",
        "1. Copy and paste the data from the serial output to punch.csv\n",
        "1. Clear the console data\n",
        "1. Push the button, flex\n",
        "1. Repeat 10x\n",
        "1. Copy and paster the serial output to flex.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg",
        "colab_type": "text"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the files tab\n",
        "1. Drag `punch.csv` and `flex.csv` files from your computer to the tab to upload them into colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK9vX9Mumlaf",
        "colab_type": "text"
      },
      "source": [
        "# TODO\n",
        "Add a test for uploaded models here\n",
        "\n",
        "List the file names in /content/*.csv\n",
        "\n",
        "Throw an error if we don't see any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg",
        "colab_type": "text"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "The next cell parses the csv and trains a fully connected neural network.\n",
        "\n",
        "Update the `GESTURES` list with the gesture data you've collected in `.csv` format.\n",
        "\n",
        "The models performance vs validation will also be graphed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version =\", tf.__version__)\n",
        "\n",
        "# set a fixed random seed for reproducibility\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# the list of gestures that data is available for\n",
        "GESTURES = [\n",
        "    \"punch\",\n",
        "    \"flex\",\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 119\n",
        "\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  gesture = GESTURES[gesture_index]\n",
        "  print(gesture_index, gesture)\n",
        "  \n",
        "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "  \n",
        "  df = pd.read_csv(\"/content/\" + gesture + \".csv\")\n",
        "  \n",
        "  # TODO this name is confusing because of NUM_GESTURES\n",
        "  # maybe num_samples?\n",
        "  num_gestures = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "  \n",
        "  print(num_gestures)\n",
        "  \n",
        "  for i in range(num_gestures):\n",
        "    tensor = []\n",
        "    for j in range(SAMPLES_PER_GESTURE):\n",
        "      index = i * SAMPLES_PER_GESTURE + j\n",
        "      tensor += [\n",
        "          df['aX'][index],\n",
        "          df['aY'][index],\n",
        "          df['aZ'][index],\n",
        "          df['gX'][index],\n",
        "          df['gY'][index],\n",
        "          df['gZ'][index]\n",
        "      ]\n",
        "\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "    \n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "\n",
        "# Randomize the order of the inputs\n",
        "# frome: https://stackoverflow.com/a/37710486/2020087\n",
        "# TODO this might be a better way to do the randomization https://stackoverflow.com/a/30633632\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# TODO are we splitting each group of 119 samples or just rows of data?\n",
        "# spit the data into three bins: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(15, activation='softmax'))\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES))\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
        "\n",
        "# graph the loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# graph the loss again skipping a bit of the start\n",
        "SKIP = 100\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# graph of mean absolute error\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(predictions)\n",
        "print(outputs_test)\n",
        "\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "# plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym",
        "colab_type": "text"
      },
      "source": [
        "# Convert Trained Model to Tensor Flow Light\n",
        "\n",
        "The next cell converts the model to TFlite format. It also creates a quantized model, that we'll ignore for now. The size in bytes of each model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab_type": "code",
        "outputId": "47713959-42b6-46f8-fd3a-9dbdc91bc5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "# Save the model to disk\n",
        "open(\"gesture_model_quantized.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Basic model is %d bytes\" % basic_model_size)\n",
        "quantized_model_size = os.path.getsize(\"gesture_model_quantized.tflite\")\n",
        "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
        "difference = basic_model_size - quantized_model_size\n",
        "print(\"Difference is %d bytes\" % difference)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basic model is 147764 bytes\n",
            "Quantized model is 40712 bytes\n",
            "Difference is 107052 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX",
        "colab_type": "text"
      },
      "source": [
        "## Encode the Model in an Arduino Header File \n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab_type": "code",
        "outputId": "ee699e0e-8c57-4116-ffe5-781856f7d571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel. Double click model.h to download the file.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Header file, model.h, is 911,246 bytes.\n",
            "\n",
            "Open the side panel. Double click model.h to download the file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5OIXC6Lc_sT",
        "colab_type": "text"
      },
      "source": [
        "# Arduino Sketch - Detect Gestures\n",
        "```\n",
        "#include <Arduino_LSM9DS1.h>\n",
        "\n",
        "#include <TensorFlowLite.h>\n",
        "#include \"tensorflow/lite/experimental/micro/kernels/all_ops_resolver.h\"\n",
        "#include \"tensorflow/lite/experimental/micro/micro_error_reporter.h\"\n",
        "#include \"tensorflow/lite/experimental/micro/micro_interpreter.h\"\n",
        "#include \"tensorflow/lite/schema/schema_generated.h\"\n",
        "#include \"tensorflow/lite/version.h\"\n",
        "\n",
        "#include \"model.h\"\n",
        "\n",
        "const int buttonPin = 3;     // the number of the pushbutton pin\n",
        "const int ledPin =  13;      // the number of the LED pin\n",
        "const int numSamples = 119;\n",
        "\n",
        "int previousButtonState = HIGH;\n",
        "int samplesRead = numSamples;\n",
        "\n",
        "// Globals, used for compatibility with Arduino-style sketches.\n",
        "tflite::ErrorReporter* g_error_reporter = nullptr;\n",
        "const tflite::Model* g_model = nullptr;\n",
        "tflite::MicroInterpreter* g_interpreter = nullptr;\n",
        "TfLiteTensor* g_input = nullptr;\n",
        "TfLiteTensor* g_output = nullptr;\n",
        "int g_inference_count = 0;\n",
        "\n",
        "// Create an area of memory to use for input, output, and intermediate arrays.\n",
        "// Finding the minimum value for your model may require some trial and error.\n",
        "constexpr int g_tensor_arena_size = 8 * 1024;\n",
        "uint8_t g_tensor_arena[g_tensor_arena_size];\n",
        "\n",
        "const char* GESTURES[] = {\n",
        "  \"punch\",\n",
        "  \"flex\"\n",
        "};\n",
        "\n",
        "#define NUM_GESTURES (sizeof(GESTURES) / sizeof(GESTURES[0]))\n",
        "\n",
        "// The name of this function is important for Arduino compatibility.\n",
        "void setup() {\n",
        "  Serial.begin(9600);\n",
        "  while (!Serial);\n",
        "\n",
        "  // initialize the LED pin as an output:\n",
        "  pinMode(ledPin, OUTPUT);\n",
        "  // initialize the pushbutton pin as an input with pullup:\n",
        "  pinMode(buttonPin, INPUT_PULLUP);\n",
        "\n",
        "  if (!IMU.begin()) {\n",
        "    Serial.println(\"Failed to initialize IMU!\");\n",
        "    while (1);\n",
        "  }\n",
        "\n",
        "  Serial.print(\"Accelerometer sample rate = \");\n",
        "  Serial.print(IMU.accelerationSampleRate());\n",
        "  Serial.println(\" Hz\");\n",
        "  Serial.print(\"Gyroscope sample rate = \");\n",
        "  Serial.print(IMU.gyroscopeSampleRate());\n",
        "  Serial.println(\" Hz\");\n",
        "\n",
        "  Serial.println();\n",
        "\n",
        "  // Set up logging\n",
        "  static tflite::MicroErrorReporter micro_error_reporter;\n",
        "  g_error_reporter = &micro_error_reporter;\n",
        "\n",
        "  // Map the model into a usable data structure. This doesn't involve any\n",
        "  // copying or parsing, it's a very lightweight operation.\n",
        "  g_model = tflite::GetModel(model);\n",
        "  if (g_model->version() != TFLITE_SCHEMA_VERSION) {\n",
        "    g_error_reporter->Report(\n",
        "      \"Model provided is schema version %d not equal \"\n",
        "      \"to supported version %d.\\n\",\n",
        "      g_model->version(), TFLITE_SCHEMA_VERSION);\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  // This pulls in all the operation implementations we need\n",
        "  static tflite::ops::micro::AllOpsResolver resolver;\n",
        "\n",
        "  // Build an interpreter to run the model with\n",
        "  static tflite::MicroInterpreter interpreter(\n",
        "    g_model, resolver, g_tensor_arena, g_tensor_arena_size, g_error_reporter);\n",
        "  g_interpreter = &interpreter;\n",
        "\n",
        "  // Allocate memory from the tensor_arena for the model's tensors\n",
        "  g_interpreter->AllocateTensors();\n",
        "\n",
        "  // Obtain pointers to the model's input and output tensors\n",
        "  g_input = g_interpreter->input(0);\n",
        "  g_output = g_interpreter->output(0);\n",
        "\n",
        "\n",
        "  // Keep track of how many inferences we have performed\n",
        "  g_inference_count = 0;\n",
        "}\n",
        "\n",
        "// The name of this function is important for Arduino compatibility.\n",
        "void loop() {\n",
        "  int buttonState = digitalRead(buttonPin);\n",
        "\n",
        "  if (buttonState != previousButtonState) {\n",
        "    if (buttonState == LOW) {\n",
        "      if (samplesRead == numSamples) {\n",
        "        // pressed       }\n",
        "        samplesRead = 0;\n",
        "      }\n",
        "    } else {\n",
        "      // released\n",
        "    }\n",
        "\n",
        "    previousButtonState = buttonState;\n",
        "  }\n",
        "\n",
        "  if (samplesRead < numSamples) {\n",
        "    if (IMU.accelerationAvailable() && IMU.gyroscopeAvailable()) {\n",
        "      float aX, aY, aZ, gX, gY, gZ;\n",
        "\n",
        "      IMU.readAcceleration(aX, aY, aZ);\n",
        "      IMU.readGyroscope(gX, gY, gZ);\n",
        "\n",
        "      g_input->data.f[samplesRead * 6 + 0] = aX;\n",
        "      g_input->data.f[samplesRead * 6 + 1] = aY;\n",
        "      g_input->data.f[samplesRead * 6 + 2] = aZ;\n",
        "      g_input->data.f[samplesRead * 6 + 3] = gX;\n",
        "      g_input->data.f[samplesRead * 6 + 4] = gY;\n",
        "      g_input->data.f[samplesRead * 6 + 5] = gZ;\n",
        "\n",
        "      samplesRead++;\n",
        "\n",
        "      if (samplesRead == numSamples) {\n",
        "        // Run inference, and report any error\n",
        "        TfLiteStatus invoke_status = g_interpreter->Invoke();\n",
        "        if (invoke_status != kTfLiteOk) {\n",
        "          g_error_reporter->Report(\"Invoke failed on x_val: %f\\n\",\n",
        "                                   static_cast<double>(0.0));\n",
        "          while (1);\n",
        "          return;\n",
        "        }\n",
        "\n",
        "        // Read the predicted y value from the model's output tensor\n",
        "        float y_val = g_output->data.f[0];\n",
        "\n",
        "        for (int i = 0; i < NUM_GESTURES; i++) {\n",
        "          Serial.print(GESTURES[i]);\n",
        "          Serial.print(\": \");\n",
        "          Serial.println(g_output->data.f[i], 6);\n",
        "        }\n",
        "        Serial.println();\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLAkFKl-yZSL",
        "colab_type": "text"
      },
      "source": [
        "## Arduino BLE Keyboard\n",
        "\n",
        "TODO Arduino / BLE HID code goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR1OccoHyhCk",
        "colab_type": "text"
      },
      "source": [
        "# Add More Gestures\n",
        "\n",
        "Now that you have this working... Load the code to record gestures. Create more CSV files with gestures. Retrain the model. Load the new model back onto the Arduino.\n",
        "\n",
        "Note: you'll need to edit the code to add the names of the new geture files."
      ]
    }
  ]
}