{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GestureToEmoji_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RkR-LZ8gdKJ",
        "colab_type": "text"
      },
      "source": [
        "#Inspiration\n",
        "\n",
        "https://dev.to/devdevcharlie/play-street-fighter-with-body-movements-using-arduino-and-tensorflow-js-4kbi\n",
        "\n",
        "Built in JS with Johnny-Five and TensorFlow.js, goal is to port it to TensorFlow Lite Micro and run ML inferencing directly on an Arduino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7P8msYEMWRd",
        "colab_type": "text"
      },
      "source": [
        "# Arduino Development Environment setup\n",
        "\n",
        "1. Download the Arduino IDE\n",
        "1. Open the Arduino IDE\n",
        "1. Install Nano 33 BLE board support via: `Tools -> Board: ... -> Board Manager ...`\n",
        "1. Install the `Arduino_LSM9DS1` library via: `Sketch -> Include Library -> Manage Libraries ...`\n",
        "1. Download: https://storage.googleapis.com/tensorflow-nightly/github/tensorflow/tensorflow/lite/experimental/micro/tools/make/gen/arduino_x86_64/prj/tensorflow_lite.zip\n",
        "1. Import downloaded library: `Sketch -> Include Library -> Add .ZIP library ...`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2h7N4yHr9MN",
        "colab_type": "text"
      },
      "source": [
        "# Hardware setup\n",
        "\n",
        "1. Insert Arduino Nano 33 BLE Sense board into mini breadboard\n",
        "1. Insert button between the GND and D3 pin\n",
        "1. Plug in micro USB cable to board and into PC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qavPmyLmsmIb",
        "colab_type": "text"
      },
      "source": [
        "# Testing hardware\n",
        "\n",
        "1. In the Arduino IDE, select: `Tools -> Board: ... -> Nano 33 BLE`\n",
        "1. Select the Serial Port for the board: `Tools -> Port -> `\n",
        "1. Open `Button` example: `File -> Examples -> 02.Digital -> Button`\n",
        "1. Change `const int buttonPin = 2;` line to `const int buttonPin = 3;` (to match the pin we placed the button on)\n",
        "1. Change the `pinMode(buttonPin, INPUT);` line to `pinMode(buttonPin, INPUT_PULLUP);` (as we will use an internal pullup resistor)\n",
        "1. Press the `Upload` button\n",
        "1. After uploading, the orange LED should remain on.\n",
        "1. Press the button, the LED should go off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcHQFDm7uvpc",
        "colab_type": "text"
      },
      "source": [
        "# Visualize IMU Data\n",
        "\n",
        "1. Download and upload the https://github.com/sandeepmistry/aimldevfest-workshop-2019/blob/master/ArduinoSketches/IMU_Capture/IMU_Capture.ino sketch to the board\n",
        "\n",
        "1. Open the Serial Monitor: `Tools -> Serial Monitor`\n",
        "1. Press the button, IMU data will be captured and outputted for 1 second\n",
        "1. Close the Serial Monitor window\n",
        "1. Open the Serial Plotter: `Tools -> Serial Plotter`\n",
        "1. Press the button, and perform a gesture\n",
        "1. You'll see a graph of the data capture\n",
        "1. Repeat capturing various gestures to get a sense of what the training data looks like\n",
        "1. Close the Serial Plotter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW62ifxErYG1",
        "colab_type": "text"
      },
      "source": [
        "# Gather Data Training\n",
        "\n",
        "1. Press the reset button on the board\n",
        "1. Open the Serial Monitor: Tools -> Serial Monitor\n",
        "1. Push the button, make a punch gesture\n",
        "1. Repeat 10x\n",
        "1. Copy and paste the data from the serial output to punch.csv\n",
        "1. Close the Serial Monitor\n",
        "1. Press the reset button on the board\n",
        "1. Open the Serial Monitor: Tools -> Serial Monitor\n",
        "1. Push the button, flex\n",
        "1. Repeat 10x\n",
        "1. Copy and paster the serial output to flex.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-",
        "colab_type": "text"
      },
      "source": [
        "# Setup Python Environment \n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install tensorflow==2.0.0-rc1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg",
        "colab_type": "text"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the files tab\n",
        "1. Drag `punch.csv` and `flex.csv` files from your computer to the tab to upload them into colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK9vX9Mumlaf",
        "colab_type": "text"
      },
      "source": [
        "# TODO\n",
        "Add a test for uploaded models here\n",
        "\n",
        "List the file names in /content/*.csv\n",
        "\n",
        "Throw an error if we don't see any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg",
        "colab_type": "text"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "The next cell parses the csv and trains a fully connected neural network.\n",
        "\n",
        "Update the `GESTURES` list with the gesture data you've collected in `.csv` format.\n",
        "\n",
        "The models performance vs validation will also be graphed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version =\", tf.__version__)\n",
        "\n",
        "# set a fixed random seed for reproducibility\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# the list of gestures that data is available for\n",
        "GESTURES = [\n",
        "    \"punch\",\n",
        "    \"flex\",\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 119\n",
        "\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  gesture = GESTURES[gesture_index]\n",
        "  print(gesture_index, gesture)\n",
        "  \n",
        "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "  \n",
        "  df = pd.read_csv(\"/content/\" + gesture + \".csv\")\n",
        "  \n",
        "  # calculate the number of gesture recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "  \n",
        "  print(num_recordings)\n",
        "  \n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    for j in range(SAMPLES_PER_GESTURE):\n",
        "      index = i * SAMPLES_PER_GESTURE + j\n",
        "      tensor += [\n",
        "          df['aX'][index],\n",
        "          df['aY'][index],\n",
        "          df['aZ'][index],\n",
        "          df['gX'][index],\n",
        "          df['gY'][index],\n",
        "          df['gZ'][index]\n",
        "      ]\n",
        "\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "    \n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "\n",
        "# Randomize the order of the inputs\n",
        "# frome: https://stackoverflow.com/a/37710486/2020087\n",
        "# TODO this might be a better way to do the randomization https://stackoverflow.com/a/30633632\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# TODO are we splitting each group of 119 samples or just rows of data?\n",
        "# --> group of samples (I've called it a recording above)\n",
        "# spit the data into three bins: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(15, activation='softmax'))\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES))\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
        "\n",
        "# graph the loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# graph the loss again skipping a bit of the start\n",
        "SKIP = 100\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# graph of mean absolute error\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(predictions)\n",
        "print(outputs_test)\n",
        "\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "# plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym",
        "colab_type": "text"
      },
      "source": [
        "# Convert Trained Model to Tensor Flow Light\n",
        "\n",
        "The next cell converts the model to TFlite format. It also creates a quantized model, that we'll ignore for now. The size in bytes of each model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "# Save the model to disk\n",
        "open(\"gesture_model_quantized.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Basic model is %d bytes\" % basic_model_size)\n",
        "quantized_model_size = os.path.getsize(\"gesture_model_quantized.tflite\")\n",
        "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
        "difference = basic_model_size - quantized_model_size\n",
        "print(\"Difference is %d bytes\" % difference)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX",
        "colab_type": "text"
      },
      "source": [
        "## Encode the Model in an Arduino Header File \n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel. Double click model.h to download the file.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId",
        "colab_type": "text"
      },
      "source": [
        "# Classifying IMU Data\n",
        "\n",
        "1. Download https://github.com/sandeepmistry/aimldevfest-workshop-2019/blob/master/ArduinoSketches/IMU_Classifier/IMU_Classifier.ino sketch\n",
        "1. Create a new tab named `model.h`, and place the `model.h` generated in the previous code cell inside it.\n",
        "1. Upload the sketch\n",
        "1. Open the Serial Monitor: `Tools -> Serial Monitor`\n",
        "1. Press the button, and perform a gesture\n",
        "1. The confidence of each gesture will be printed to the Serial Monitor (0 -> low confidence, 1 -> high confidence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR1OccoHyhCk",
        "colab_type": "text"
      },
      "source": [
        "# Add More Gestures\n",
        "\n",
        "Now that you have this working... Load the code to record gestures. Create more CSV files with gestures. Retrain the model. Load the new model back onto the Arduino.\n",
        "\n",
        "Note: you'll need to edit the code to add the names of the new geture files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLAkFKl-yZSL",
        "colab_type": "text"
      },
      "source": [
        "## Arduino BLE Keyboard\n",
        "\n",
        "TODO Arduino / BLE HID code goes here\n"
      ]
    }
  ]
}