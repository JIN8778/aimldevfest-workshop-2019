## These are the notes for the Arduino ML workshop
## Ideally we'll use this as a guide for speaking and to make the slides
## 

Welcome

Make sure people are in the right workshop

Get the machines setup ASAP
   Arduino IDE + Nano 33 definitions + IMU library
   Link to instructions for Linux users. If you're a linux user, you better be able to follow instructions. I'm not your linux admin.
   What about people with a locked down Windows 7 machine?
   What about people with Windwows 10 and no admin?

People can use the Arduino Cloud IDE if they want.

Need to start downloading and installing ASAP beacuse the Nano 33 definitions can take a long time (and not just the slow network part.)

----

TODO title here

Introduce ourselves

Overview of what we're doing today

    ML-Powered Gesture-based emoji keyboard

    Sandeep's inspiration
        Show video?

    Why ML on a device - borrow explanation from the TinyML book
    TODO link


What is ML?
   
   I know this is a AI ML dev fest, so many of you are familiar with ML, but it was also a low cost event where you can learn stuff and you're in a workshop. So what is ML, we're going us a machine to find patterns in data. Based on these patterns, we'll have a trained model that should be able to recognize (or match) the pattern when it happens again. TODO - add some better info here

Hardware

    Provided by Arduino! Thank you.

    Overview of the Hardware
        ARM Cortex ???
        IMU
        Good for ML because ... (insert cool reasons here)
                
        "The nRF52840 is fully multiprotocol capable with full protocol concurrency. It has protocol support for Bluetooth 5, Bluetooth mesh, Thread, Zigbee, 802.15.4, ANT and 2.4 GHz proprietary stacks. The nRF52840 is built around the 32-bit ARM® Cortex™-M4 CPU with floating point unit running at 64 MHz."
https://www.nordicsemi.com/?sc_itemid=%7B2DC10BA5-A76E-40F8-836E-E2FC65803A71%7D

         More info about the other sensors on the board that we're not using

The Technology

    Accelerometer & Gyro - record data
    TensorFlow - train model
    TensorFlow light - run model on tiny hardware
    Arduino - nice approachable hardware programming environment with excellent libraries
    Google Colab - Python + Jupyter Notebooks
    
    Something about nRF52
    WTF is an IMU
   
Recording data

    What we're recording
    How we do it
    How many times / How much data
    Why 119?
    
Visualize the data

    Use Arduino IDE to graph

Copy and paste gesture output to CSV file

    Include the headers ax, ay, az, gx, gy, gz
    name it punch.csv
    (or don't and update the code)

Repeat for the flex Gesture
    name the file flex.csv

Training the model
    We don't do this on the MCU, we need a real computer
    We use TensorFlow and Python
    Jupyter Notebooks help us organize stuff
        Convenient way to write and share code with an explanation
        Can run Jupyter locally
        Can run on Databricks, Microsoft Azure etc.
        Today we're running on Google Colab. It's a great environment to experiement with ML

    Open the Notebook (from public github)
    Note / Warning about cookies and how to work around

    What is machine learning 
        (Should have we talked about this earlier? )
        More than just if statements (or not)
        What type of ML are we doing today
        Categorization
        Fancy Pattern matching
        (Sandeep: can you help explain this better here.)

    ??? Do we run the whole training part or can we break up into phases

    Now we have a TF model
        WTF is a model
        What does it Include
        How does it work? High level, conceptually

    But the Arduino can't handle the TF model. We convert this to TensorFlow Lite
         https://www.tensorflow.org/lite/performance/post_training_quantization

    Even though it's TF lite, we can't easily add it to Arduino
        Convert into an array so we can include in the Arduino header file
    
    Matching code

    Run it

    Bluetooth keyboard

    Run it

    Go back, add more gesture. Repeat the process.
    
    
Other stuff to (possibly) add in
   What are the limitations of this demo?
   How can this be expanded to a real world situation?
   Where would I use ML on embedded devices?
   How do I get the data? What makes good data vs bad data?
   How do I build models to train?






